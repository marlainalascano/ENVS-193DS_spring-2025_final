---
title: "ENVS-193DS_spring-2025_final.git"
author: "Marlaina Lascano"
date: "06/11/25"
format: docx
---

## Quarto

Git Hub Repo - <https://github.com/marlainalascano/ENVS-193DS_spring-2025_final>

```{r}
#load packages 
library(tidyverse)
library(DHARMa) #3f
library(gt)
library(MuMIn) #3g
library(lubridate)
library(viridis)
library(janitor)
library(ggplot2)
library(readxl)
library(ggpubr)
library(dplyr)

sst <- read_csv("data/SST_update2023.csv") #read in problem 2 data
data <- read_csv("data/occdist.csv") #read in problem 3 data
```

## Problem 1

### a)

In part 1, the co-worker likely used a correlation analysis or a linear regression . The reported p-value of 0.03 suggests they were testing whether the slope of the relationship between the two variables is significantly different from zero.

In part 2, the co-worker might have used a one-way ANOVA (Analysis of Variance). The p-value of 0.02 suggests that at least one group has a significantly different mean nitrogen load compared to the others.

### b)

1.  A post-hoc test like Tukey’s Honest Significant Difference (HSD) could be performed to determine which specific nitrogen sources differ significantly from each other. Tukey’s HSD would allow you to tell whether fertilizer sources have significantly higher nitrogen loads than atmospheric deposition or grasslands, which is crucial for making management recommendations.
2.  Including a table or summary statistic that reports the mean nitrogen load and standard deviation for each source would help someone understand the variability of nitrogen contributions from each source. Providing descriptive statistics gives context to the ANOVA results and helps audiences grasp which sources are contributing the most nitrogen on average and know that there is more than just a difference.

### c)

1.  As th distance from the headwater increases, there is a statistically significant corelation with the annual total nitrogen load (kg year-1), which suggests a possible pattern in water contamination like nutritional build up or runoff. (Statistical test: Pearson correlation; r = \[correlation coefficient\], p = 0.03, α = 0.05)
2.  Through our tests we observed a significant variation in average nitrogen load across different sources, meaning that some sources may contribute more to nutritional pollution and contamination than others. (Statistical test: ANOVA; F = (F stat), df = (deg freedom), p = 0.02, α = 0.05)

## Problem 2

### a)

```{r}

#cleaning data
sst_clean <- sst|> 
  select(date, temp) |> #get rid of long and lat
  mutate(
    year = year(date),                    #extract year
    month = month(date, label = TRUE)    #extract month
  ) |> 
  
  group_by(year, month) |> #group by year and month
  summarise(mean_monthly_sst = mean(temp, na.rm = TRUE)) |> #calculate monthly sst
  
  mutate(
    year = as.factor(year),
    month = factor(month, levels = month.abb, ordered = TRUE) #order months in correct order
  ) |> 
  ungroup()


sst_clean |> 
  slice_sample(n = 5) #showing 5 random rows of cleaned data

str(sst_clean) #show the requested structure
```

### b)

```{r}
sst_subset <- sst_clean %>% #use clean data
  filter(year %in% c("2018", "2019", "2020", "2021", "2022", "2023")) #only want 2018-2023

#creating plot
ggplot(data = sst_subset, aes(x = month, y = mean_monthly_sst, group = year, color = year)) +
  geom_line(linewidth = 1) + #size of connecting lines
  geom_point(size = 2) + #size of dots
  scale_color_manual(
    values = colorRampPalette(c("#7cadf5", "#08306b"))(6)  #blue gradient
  ) +
  labs(
    x = "Month", #x axis title
    y = "Mean monthly sea surface temperature (°C)", #y axis title
    color = "Year" #legend title
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = c(0.1, 0.7), #legend on the top left
    legend.background = element_rect(fill = "white", color = "white"), #no border on table of contents
    panel.border = element_rect(color = "black", fill = NA), #outline of box in graph
    panel.background = element_rect(fill = "white"), #background color is white
    panel.grid.major = element_blank(),  #remove grid lines
    panel.grid.minor = element_blank(),  #remove grid lines
    axis.title = element_text(size = 12), #size of axis title
     axis.text = element_text(size = 10), #size of axis text
    legend.title = element_text(size = 12), #size of legend title
    legend.text = element_text(size = 10) #size of legend text internal
  )
```

## Problem 3

### a)

Biologically the 1's and 0's in this data set represent what bird, if any, is in the nest box during the given breeding season. Depending on which column you look at 1 means there is a Swift Parrot, Tree Martin, Common Starling, or no bird.

### b)

Swift Parrots are a critically endangered species while tree Martins and Common Starlings are more common and considered competition for different recources.

### c)

The 'seasons' they are talking about are the 2016 and 2019 summer breeding seasons when parrots bred at the study area. These seasons differ because a lot can change in 3 years, such as, average global temperature, management practices, weather patterns, populations of different supporting or threatening species, and increased or decreased compettition if other populations change over the years.

### d. Table of Models

| Model \# | Season Included | Distance from Edge Included | Model Description |
|----------|-----------------|-----------------------------|-------------------|
| 1        | No              | No                          | Null model        |
| 2        | Yes             | Yes                         | Saturated model   |
| 3        | Yes             | No                          | Season model      |
| 4        | No              | Yes                         | Distance model    |

### e)

```{r}

data <- data %>%
  rename(edge_distance = `edge distance`) %>%
  mutate(season = as.factor(season)) #cleaning data

model1 <- glm(sp ~ 1, data = data, family = "binomial") #intercept only null model

model2 <- glm(sp ~ season + edge_distance, data = data, family = "binomial") #sason and edge saturated model

model3 <- glm(sp ~ season, data = data, family = "binomial") #season only

model4 <- glm(sp ~ edge_distance, data = data, family = "binomial") # distance only


```

### f)

```{r}

simulation1 <- simulateResiduals(model1)
plot(simulation1, main = "Diagnostics for Model 1") #Model 1 diagnostics
  
simulation3 <- simulateResiduals(model3)
plot(simulation3, main = "Diagnostics for Model 3") #Model 3 diagnostics

simulation4 <- simulateResiduals(model4)
plot(simulation4, main = "Diagnostics for Model 4") #Model 4 diagnostics

simulation2 <- simulateResiduals(model2)
plot(simulation2, main = "Diagnostics for Model 2") #Model 2 diagnostics

```

### g)

```{r}
model.sel(model1, model2, model3, model4)
```

The best model as determined by Akaike’s Information Criterion (AIC) was model2. This model had the lowest AICc value (226.3), meaning it has the balance of goodness-of-fit and model simplicity compared to the other models.

### h)

```{r}
new_data <- expand.grid(
  edge_distance = seq(0, 900, by = 10),
  season = factor(c(2016, 2019), levels = levels(data$season))  #new dataframe for edge distances during both seasons
)


preds <- predict(model2, newdata = new_data, type = "link", se.fit = TRUE) #Get predicted probabilities and confidence intervals
new_data$fit <- preds$fit
new_data$se <- preds$se.fit

new_data <- new_data %>%
  mutate(prob = plogis(fit),
         lower = plogis(fit - 1.96 * se),
         upper = plogis(fit + 1.96 * se)) #Convert from logit to probability scale


ggplot(new_data, aes(x = edge_distance, y = prob, color = factor(season))) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = lower, ymax = upper, fill = factor(season)), alpha = 0.2, color = NA) +
  labs(
    x = "Distance to Forest Edge (m)", #x axis title
    y = "Probability of Swift Parrot Occupancy", #y axis title
    color = "Season", 
    fill = "Season" #legend title
  ) +
  scale_color_manual(values = c("#5b4d9f", "#e01f51")) +
  scale_fill_manual(values = c("#5b4d9f", "#e01f51")) +
  theme_minimal(base_size = 14) +
  theme(panel.grid = element_blank())
```

### i)

**Figure 1. Predicted Probability of Swift Parrot Nest Box Occupancy by Distance to Forest Edge**\
This figure shows the predicition of probability of the Swift Parrot occupancy in nest boxes in corelation to its distance to the forrest's edge during the breeding season 2016 and 2019 and 95% confidence intervals. These values are predicted based on logistic regression model with both season and edge distance as predictors.
**Data source**: Stojanovic et al. (2021). Dryad. <https://doi.org/10.5061/dryad.83bk3j9sb>

### j)

```{r}

edge_points <- data.frame(
  edge_distance = c(0, 900),
  season = c(2016, 2016, 2019, 2019) # new data frame for edge distances we are interested in
)

edge_points <- expand.grid(
  edge_distance = c(0, 900),
  season = factor(c(2016, 2019), levels = levels(data$season))  #match factor levels
)

edge_pred <- predict(model2, newdata = edge_points, type = "link", se.fit = TRUE) #Predict on link scale

edge_points$fit <- edge_pred$fit
edge_points$se <- edge_pred$se.fit
edge_points <- edge_points %>%
  mutate(prob = plogis(fit),
         lower = plogis(fit - 1.96 * se),
         upper = plogis(fit + 1.96 * se)) #Add predictions and convert to probability scale


edge_points #shows output
```

### k)

## Problem 4

### a)

The Homework 3 graph is an effective bar chart, using color and categorical grouping (sleep and protein levels) to emphasize mood differences. It also compares multiple variables at one time to find the optimal mix. The Homework 2 visualizations are more straightforward: There is a Q-Q plot with confidence intervals, used to check normality, a box plot showing distributions and outliers of PM2.5 levels by location, and a time series line plot comparing PM2.5 levels over time across multiple locations. These graphs focus on data exploration and distribution rather than emotional storytelling.

All the graphs in Homework 2 and 3 have a clean look to them, including an axis title to help the view interpret the trends and differences. Each plot involves comparisons from 2 or more categories whether that be location or conditions. They also use individual data points to show the variability.

In the Homework 3 graph, we can see a pattern of a higher mood score when more protein is consumed and more sleep is had, showing a pattern of better well being with these factors. In the Homework 2 visuals, the Q-Q plot shows deviation from the normal in the tails, most likely due to PM2.5 outliers. The box plot shows a higher median and more extreme outliers, and the line plot shows higher PM2.5 levels over time, especially in the start of December. We can see these differences arise because the Homework 3 graph is emphasizing categorical interactions while the Homework 2 graphs are exploring distribution and variation in environmental trends.

Some Feedback I got in week 9 was to make sure my visuals are clear and readable, and tell the story I am trying to tell. I implemented this in my Homework 3 graph by pairing a bar chart and a scatter plot, so you can see 2 things at once without getting confused at what is happening. I was also told to be careful with my placement of things like the legend and titles so that they don't overlap. I implemented this in my Homework 3 as well, making sure my visual was perfect and professional before turning it in. 

\
